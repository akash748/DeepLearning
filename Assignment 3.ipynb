{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3a57287",
   "metadata": {},
   "source": [
    "Question 1:Is it OK to initialize all the weights to the same value as long as that value is selected randomly using He initialization?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfceee23",
   "metadata": {},
   "source": [
    "No the weights should never be initialized to the same value because it will fail in the backward propogation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c486429d",
   "metadata": {},
   "source": [
    "Question 2:Is it OK to initialize the bias terms to 0?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30693640",
   "metadata": {},
   "source": [
    "It is completely fine to initilaize the bias term to zero."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73b9a03d",
   "metadata": {},
   "source": [
    "Question 3:Name three advantages of the SELU activation function over ReLU."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4414b53",
   "metadata": {},
   "source": [
    "Similar to ReLUs, SELUs enable deep neural networks since there is no problem with vanishing gradients.\n",
    "\n",
    "In contrast to ReLUs, SELUs cannot die.\n",
    "\n",
    "SELUs on their own learn faster and better than other activation functions, even if they are combined with batch normalization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d2c92a",
   "metadata": {},
   "source": [
    "Question 4:In which cases would you want to use each of the following activation functions: SELU, leaky ReLU (and its variants), ReLU, tanh, logistic, and softmax?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac90f5c0",
   "metadata": {},
   "source": [
    "Tanh function graphically looks very similar to sigmoid apart from being centered between -1 and 1. The main advantage of this is that the negative inputs will be mapped strongly negative and the zero inputs will be mapped near zero. The tanh function is mainly used in scenarios where we want to perform a classification between two classes. Regrettably, this activation function is also affected by the vanishing gradient problem, so network layer size must be considered."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb3594af",
   "metadata": {},
   "source": [
    "Softmax is a more generalized logistic activation function mostly used for classification problems in which we have multiple classes, not just binary. It is able to map each output in such a way that the total sum is equal to 1. Since the output is a probability distribution, softmax is normally used in the final layer of a neural network classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f10e48a9",
   "metadata": {},
   "source": [
    "ReLU (Rectified Linear units) is a very simple and efficient activation function that has became very popular recently, especially in CNNs. It avoids and rectifies the vanishing gradient problem, which mostly explains why it’s used in almost all deep learning problems nowadays."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aa38411",
   "metadata": {},
   "source": [
    "Leaky ReLU and PReLU (Parametric ReLU) introduce few modifications to ReLU. Both alternatives provide a small slope for negative ranges, static for Leaky ReLU, and as a parameter for PReLU. This way, the “dying” ReLU problem is completely solved as it doesn’t have zero-slope parts. They also slightly speed up training, being more balanced and learning faster. These alternatives might be considered for scenarios where the training process takes too long, in order to avoid inactive neurons in the network."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb013c2",
   "metadata": {},
   "source": [
    "Similar to leaky ReLU and PReLU, both ELU and SELU provide a small slope to negative values, but using an exponential curve. They mix elements of basic ReLU and Leaky ReLU, since they provide negative values in the short-term, but remain inactive for large negative values in the long-term.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10033f4",
   "metadata": {},
   "source": [
    "Question 5:What may happen if you set the momentum hyperparameter too close to 1 (e.g., 0.99999) when using an SGD optimizer?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ccd9d84",
   "metadata": {},
   "source": [
    "High momentum value will help in smoothening of the curve and reach the global minima faster."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d91b5d",
   "metadata": {},
   "source": [
    "Question 6:Name three ways you can produce a sparse model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e48468b",
   "metadata": {},
   "source": [
    "1. A deep learning neural network can produce sparse features.\n",
    "2. Vanishing Gradient Problem.\n",
    "3. A lot of features in the dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c7a74c3",
   "metadata": {},
   "source": [
    "Question 7:Does dropout slow down training? Does it slow down inference (i.e., making predictions on new instances)? What about MC Dropout?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "222683ad",
   "metadata": {},
   "source": [
    "Yes dropout slows down the training process and speeds up the inference phase."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095983fb",
   "metadata": {},
   "source": [
    "No MC Dropout does not behave any differently w.r.t speed than the naive dropout."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e03a15",
   "metadata": {},
   "source": [
    "Question 8:Practice training a deep neural network on the CIFAR10 image dataset:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6340353",
   "metadata": {},
   "source": [
    "a) Build a CNN with 20 hidden layers of 100 neurons each (that’s too many, but it’s the point of this exercise). Use He initialization and the ELU activation function."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89a4ded6",
   "metadata": {},
   "source": [
    "b.\tUsing Nadam optimization and early stopping, train the network on the CIFAR10 dataset. You can load it with keras.datasets.cifar10.load_data(). The dataset is composed of 60,000 32 × 32–pixel color images (50,000 for training, 10,000 for testing) with 10 classes, so you’ll need a softmax output layer with 10 neurons. Remember to search for the right learning rate each time you change the model’s architecture or hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2d79c769",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_5 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_149 (Dense)            (None, 100)               2880100   \n",
      "_________________________________________________________________\n",
      "dense_150 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_151 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_152 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_153 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_154 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_155 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_156 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_157 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_158 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_159 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_160 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_161 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_162 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_163 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_164 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_165 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_166 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_167 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_168 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_169 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 3,073,906\n",
      "Trainable params: 3,073,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from time import time\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32,32,3), activation='elu', kernel_initializer='HeUniform')) \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(10,activation = 'softmax'))\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"Nadam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2cf0e8f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 84s 52ms/step - loss: 1.8333 - accuracy: 0.2977\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 81s 52ms/step - loss: 1.5293 - accuracy: 0.4240\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 81s 52ms/step - loss: 1.4210 - accuracy: 0.4778\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 81s 52ms/step - loss: 1.3152 - accuracy: 0.5236\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 81s 52ms/step - loss: 1.2297 - accuracy: 0.5614\n",
      "410.2930676937103\n"
     ]
    }
   ],
   "source": [
    "\n",
    "start = time()\n",
    "\n",
    "model.fit(x_train,y_train, epochs=5, batch_size=32)  #training\n",
    "print(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "1675d270",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 1.4015 - accuracy: 0.5048\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[1.4015452861785889, 0.504800021648407]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c231978",
   "metadata": {},
   "source": [
    "c.Now try adding Batch Normalization and compare the learning curves: Is it converging faster than before? Does it produce a better model? How does it affect training speed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b4d51a2a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_7 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "flatten_7 (Flatten)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_171 (Dense)            (None, 100)               2880100   \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_172 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_173 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_174 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_175 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_176 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_177 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_178 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_179 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_180 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_181 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_182 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_183 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_184 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_185 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_186 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_187 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 100)               400       \n",
      "_________________________________________________________________\n",
      "dense_188 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_189 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_190 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_191 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 3,075,506\n",
      "Trainable params: 3,074,706\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from time import time\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32,32,3), activation='elu', kernel_initializer='HeUniform')) \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(10,activation = 'softmax'))\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"Nadam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "ac6c76a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 85s 52ms/step - loss: 1.6438 - accuracy: 0.4015\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 83s 53ms/step - loss: 1.3628 - accuracy: 0.5186\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 82s 53ms/step - loss: 1.2131 - accuracy: 0.5744\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 83s 53ms/step - loss: 1.0868 - accuracy: 0.6231\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 82s 53ms/step - loss: 0.9702 - accuracy: 0.6655\n",
      "415.4064815044403\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "model.fit(x_train,y_train, epochs=5, batch_size=32)  #training\n",
    "print(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "817eaa6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 2.3292 - accuracy: 0.3912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.329183340072632, 0.3912000060081482]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b1d95fc",
   "metadata": {},
   "source": [
    "The training time increase and the accuracy decreased for the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aac85be8",
   "metadata": {},
   "source": [
    "d.Try replacing Batch Normalization with SELU, and make the necessary adjustements to ensure the network self-normalizes (i.e., standardize the input features, use LeCun normal initialization, make sure the DNN contains only a sequence of dense layers, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e3ec3ac4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_11\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_8 (Conv2D)            (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_192 (Dense)            (None, 100)               2880100   \n",
      "_________________________________________________________________\n",
      "dense_193 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_194 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_195 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_196 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_197 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_198 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_199 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_200 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_201 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_202 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_203 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_204 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_205 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_206 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_207 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_208 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_209 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_210 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_211 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_212 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 3,073,906\n",
      "Trainable params: 3,073,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from time import time\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32,32,3), activation='elu')) \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(100,kernel_initializer='lecun_normal',activation = 'selu'))\n",
    "model.add(Dense(100,kernel_initializer='lecun_normal',activation = 'selu'))\n",
    "model.add(Dense(100,kernel_initializer='lecun_normal',activation = 'selu'))\n",
    "model.add(Dense(100,kernel_initializer='lecun_normal',activation = 'selu'))\n",
    "model.add(Dense(100,kernel_initializer='lecun_normal',activation = 'selu'))\n",
    "model.add(Dense(100,kernel_initializer='lecun_normal',activation = 'selu'))\n",
    "model.add(Dense(100,kernel_initializer='lecun_normal',activation = 'selu'))\n",
    "model.add(Dense(100,kernel_initializer='lecun_normal',activation = 'selu'))\n",
    "model.add(Dense(100,kernel_initializer='lecun_normal',activation = 'selu'))\n",
    "model.add(Dense(100,kernel_initializer='lecun_normal',activation = 'selu'))\n",
    "model.add(Dense(100,kernel_initializer='lecun_normal',activation = 'selu'))\n",
    "model.add(Dense(100,kernel_initializer='lecun_normal',activation = 'selu'))\n",
    "model.add(Dense(100,kernel_initializer='lecun_normal',activation = 'selu'))\n",
    "model.add(Dense(100,kernel_initializer='lecun_normal',activation = 'selu'))\n",
    "model.add(Dense(100,kernel_initializer='lecun_normal',activation = 'selu'))\n",
    "model.add(Dense(100,kernel_initializer='lecun_normal',activation = 'selu'))\n",
    "model.add(Dense(100,kernel_initializer='lecun_normal',activation = 'selu'))\n",
    "model.add(Dense(100,kernel_initializer='lecun_normal',activation = 'selu'))\n",
    "model.add(Dense(100,kernel_initializer='lecun_normal',activation = 'selu'))\n",
    "model.add(Dense(100,kernel_initializer='lecun_normal',activation = 'selu'))\n",
    "\n",
    "model.add(Dense(10,activation = 'softmax'))\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"Nadam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7ffffb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 84s 53ms/step - loss: 1.8206 - accuracy: 0.3331\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 82s 53ms/step - loss: 1.4838 - accuracy: 0.4715\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 84s 54ms/step - loss: 1.3557 - accuracy: 0.5262\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 83s 53ms/step - loss: 1.2635 - accuracy: 0.5623\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 83s 53ms/step - loss: 1.1876 - accuracy: 0.5934\n",
      "417.1978087425232\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "model.fit(x_train,y_train, epochs=5, batch_size=32)  #training\n",
    "print(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "27add64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 2.3523 - accuracy: 0.1054\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.352325677871704, 0.10540000349283218]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47988ac",
   "metadata": {},
   "source": [
    "e.Try regularizing the model with alpha dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "3aa0734b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_13\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_10 (Conv2D)           (None, 30, 30, 32)        896       \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 28800)             0         \n",
      "_________________________________________________________________\n",
      "dense_234 (Dense)            (None, 100)               2880100   \n",
      "_________________________________________________________________\n",
      "dense_235 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_236 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_237 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_238 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_239 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_240 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_241 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_242 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_243 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_244 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_245 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_246 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_247 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_248 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_249 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_12 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_250 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_251 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dropout_13 (Dropout)         (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_252 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_253 (Dense)            (None, 100)               10100     \n",
      "_________________________________________________________________\n",
      "dense_254 (Dense)            (None, 10)                1010      \n",
      "=================================================================\n",
      "Total params: 3,073,906\n",
      "Trainable params: 3,073,906\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from time import time\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "from keras.layers import Dense,Dropout,Flatten,Conv2D,MaxPooling2D\n",
    "from keras.models import Sequential\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=(32,32,3), activation='elu', kernel_initializer='HeUniform')) \n",
    "model.add(Flatten()) \n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dropout(0.50))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(100,activation = 'elu'))\n",
    "model.add(Dense(10,activation = 'softmax'))\n",
    "model.compile(loss=\"sparse_categorical_crossentropy\", optimizer=\"Nadam\", metrics=[\"accuracy\"])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f0f3d140",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1563/1563 [==============================] - 85s 53ms/step - loss: 2.3935 - accuracy: 0.1068\n",
      "Epoch 2/5\n",
      "1563/1563 [==============================] - 83s 53ms/step - loss: 2.0704 - accuracy: 0.1692\n",
      "Epoch 3/5\n",
      "1563/1563 [==============================] - 83s 53ms/step - loss: 1.9647 - accuracy: 0.1878\n",
      "Epoch 4/5\n",
      "1563/1563 [==============================] - 83s 53ms/step - loss: 1.9360 - accuracy: 0.1947\n",
      "Epoch 5/5\n",
      "1563/1563 [==============================] - 83s 53ms/step - loss: 1.8759 - accuracy: 0.2441\n",
      "418.316917181015\n"
     ]
    }
   ],
   "source": [
    "start = time()\n",
    "\n",
    "model.fit(x_train,y_train, epochs=5, batch_size=32)  #training\n",
    "print(time()-start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e619ad4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 3s 8ms/step - loss: 2.5264 - accuracy: 0.1275\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[2.526355743408203, 0.1274999976158142]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.evaluate(x_test,y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

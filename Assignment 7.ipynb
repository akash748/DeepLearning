{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9c7812b2",
   "metadata": {},
   "source": [
    "Question 1: Can you think of a few applications for a sequence-to-sequence RNN? What about a sequence-to-vector RNN, and a vector-to-sequence RNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5d2366",
   "metadata": {},
   "source": [
    "Few Applications of sequence to sequence RNN is speech recognition, machine translation, image captioning and question answering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e60242f",
   "metadata": {},
   "source": [
    "For a sequence-to-vector RNN: classifying music samples by music genre, analyzing the sentiment of a book review, predicting what word an aphasic patient is thinking of based on readings from brain implants, predicting the probability that a user will want to watch a movie based on her watch history (this is one of many possible implementations of collaborative filtering)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebba7a5",
   "metadata": {},
   "source": [
    "For a vector-to-sequence RNN: image captioning, creating a music playlist based on an embedding of the current artist, generating a melody based on a set of parameters, locating pedestrians in a picture (e.g., a video frame from a self-driving car’s camera)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50f84ba3",
   "metadata": {},
   "source": [
    "Question 2: How many dimensions must the inputs of an RNN layer have? What does each dimension represent? What about its outputs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7bf57d8",
   "metadata": {},
   "source": [
    "An important thing to note is that the RNN input needs to have 3 dimensions. Typically it would be batch size, the number of steps and number of features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a542c71",
   "metadata": {},
   "source": [
    "Question 3: If you want to build a deep sequence-to-sequence RNN, which RNN layers should have return_sequences=True? What about a sequence-to-vector RNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e63ef2a",
   "metadata": {},
   "source": [
    "To handle variable length input sequences, the simplest option is to set the sequence_length parameter when calling the static_rnn() or dynamic_rnn() functions. Another option is to pad the smaller inputs (e.g., with zeros) to make them the same size as the largest input (this may be faster than the first option if the input sequences all have very similar lengths). To handle variable-length output sequences, if you know in advance the length of each output sequence, you can use the sequence_length parameter (for example, consider a sequence-to-sequence RNN that labels every frame in a video with a violence score: the output sequence will be exactly the same length as the input sequence). If you don’t know in advance the length of the output sequence, you can use the padding trick: always output the same size sequence, but ignore any outputs that come after the end-of-sequence token (by ignoring them when computing the cost function)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e542ea28",
   "metadata": {},
   "source": [
    "Question 4: Suppose you have a daily univariate time series, and you want to forecast the next seven days. Which RNN architecture should you use?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51ea21c3",
   "metadata": {},
   "source": [
    "We can use LSTM for this purpose."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e699abe6",
   "metadata": {},
   "source": [
    "Question 5: What are the main difficulties when training RNNs? How can you handle them?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e3f9231",
   "metadata": {},
   "source": [
    "The difficulty of training artificial recurrent neural networks has to do with their complexity.\n",
    "\n",
    "One of the simplest ways to explain why recurrent neural networks are hard to train is that they are not feedforward neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3073f643",
   "metadata": {},
   "source": [
    "By contrast, recurrent neural networks and other different types of neural networks have more complex signal movements. Classed as “feedback” networks, recurrent neural networks can have signals traveling both forward and back, and may contain various “loops” in the network where numbers or values are fed back into the network. Experts associate this with the aspect of recurrent neural networks that's associated with their memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ac31343",
   "metadata": {},
   "source": [
    "The problem, continues, gets worse with long sequences and more numerous time steps, in which the signals grow or decay. Weight initialization may help, but those challenges are built into the recurrent neural network model. There's always going to be that issue attached to their particular design and build. Essentially, some of the more complex types of neural networks really defy our ability to easily manage them. We can create a practically infinite amount of complexity, but we often see predictability and scalability challenges grow."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab3a25b0",
   "metadata": {},
   "source": [
    "Question 6: Can you sketch the LSTM cell’s architecture?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77c651ba",
   "metadata": {},
   "source": [
    "LSTM consists of 3 gates namely Forget Gate, Input Gate and Output Gate."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e09ab2",
   "metadata": {},
   "source": [
    "Forget Gate:\n",
    "\n",
    "A forget gate is responsible for removing information from the cell state. The information that is no longer required for the LSTM to understand things or the information that is of less importance is removed via multiplication of a filter. This is required for optimizing the performance of the LSTM network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70703405",
   "metadata": {},
   "source": [
    "Input Gate:\n",
    "\n",
    "The input gate is responsible for the addition of information to the cell state. This addition of information is basically three-step process as seen from the diagram above.\n",
    "\n",
    "Regulating what values need to be added to the cell state by involving a sigmoid function. This is basically very similar to the forget gate and acts as a filter for all the information from h_t-1 and x_t.\n",
    "Creating a vector containing all possible values that can be added (as perceived from h_t-1 and x_t) to the cell state. This is done using the tanh function, which outputs values from -1 to +1.  \n",
    "Multiplying the value of the regulatory filter (the sigmoid gate) to the created vector (the tanh function) and then adding this useful information to the cell state via addition operation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2178c67f",
   "metadata": {},
   "source": [
    "Output Gate:\n",
    "\n",
    "The functioning of an output gate can again be broken down to three steps:\n",
    "\n",
    "Creating a vector after applying tanh function to the cell state, thereby scaling the values to the range -1 to +1.\n",
    "Making a filter using the values of h_t-1 and x_t, such that it can regulate the values that need to be output from the vector created above. This filter again employs a sigmoid function.\n",
    "Multiplying the value of this regulatory filter to the vector created in step 1, and sending it out as a output and also to the hidden state of the next cell."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808ef9c7",
   "metadata": {},
   "source": [
    "<img src = \"image10.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bfb839c",
   "metadata": {},
   "source": [
    "Question 7: Why would you want to use 1D convolutional layers in an RNN?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f38cdff",
   "metadata": {},
   "source": [
    "1D convolutional neural nets can be used for extracting local 1D patches (subsequences) from sequences and can identify local patterns within the window of convolution. And because the same transformation is applied on every patch identified by the window, a pattern learnt at one position can also be recognized at a different position, making 1D conv nets translation invariant.\n",
    "\n",
    "Another interesting use case is to combine 1D conv nets with RNNs. Suppose you have a long sequence to process so long that it cannot be realistically processed by RNNs. In such cases, 1D conv nets can be used as a pre-processing step to make the sequence smaller through downsampling by extracting higher level features, which can, then be passed on to the RNN as input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f44f2fcf",
   "metadata": {},
   "source": [
    "Question 8: Which neural network architecture could you use to classify videos?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fe6e7ed",
   "metadata": {},
   "source": [
    "To classify videos based on the visual content, one possible architecture could be to take (say) one frame per second, then run each frame through a convolutional neural network, feed the output of the CNN to a sequence-to-vector RNN, and finally run its output through a softmax layer, giving you all the class probabilities. For training you would just use cross entropy as the cost function. If you wanted to use the audio for classification as well, you could convert every second of audio to a spectrograph, feed this spectrograph to a CNN, and feed the output of this CNN to the RNN (along with the corresponding output of the other CNN)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1287eddd",
   "metadata": {},
   "source": [
    "Question 1: What are the main tasks that autoencoders are used for?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a66bca09",
   "metadata": {},
   "source": [
    "Autoencoders (AE) are neural networks that aims to copy their inputs to their outputs. They work by compressing the input into a latent-space representation, and then reconstructing the output from this representation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ef56e93",
   "metadata": {},
   "source": [
    "Applications of autoencoders include data compression, image denoising, feature extraction, image generation and image colourisation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a47df",
   "metadata": {},
   "source": [
    "Question 2: Suppose you want to train a classifier, and you have plenty of unlabeled training data but only a few thousand labeled instances. How can autoencoders help? How would you proceed?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91cccedd",
   "metadata": {},
   "source": [
    "We will create an autoencoder model in which we only show the model 1 class. The model will try to learn the best representation of that class. The same model will be used to generate the representations of other and we expect them to be different from non-fraud ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11cf3d92",
   "metadata": {},
   "source": [
    "The beauty of this approach is that we do not need too many samples of data for learning the good representations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85e26464",
   "metadata": {},
   "source": [
    "Now we are intereseted in obtaining latent representation of the input learned by the model. This can be accessed by the weights of the trained model. We will create another network containing sequential layers, and we will only add the trained weights till the third layer where latent representation exists."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35d70486",
   "metadata": {},
   "source": [
    "Generate the hidden representations of the classes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c691b60",
   "metadata": {},
   "source": [
    "Now we will create a training dataset using the latent representations obtained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13bb2a5d",
   "metadata": {},
   "source": [
    "Now we can use any classifier to get a clear boundary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fa9458d",
   "metadata": {},
   "source": [
    "Question 3: If an autoencoder perfectly reconstructs the inputs, is it necessarily a good autoencoder? How can you evaluate the performance of an autoencoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c3a16c2",
   "metadata": {},
   "source": [
    "If you consider conventional autoencoder function, yes, it is a good autoencoder. In practice, efficiency of autoencoder depends on how well it reconstructs and also on how robust it is to noise in different scenes.\n",
    "\n",
    "Common practice is to add noise sampled from input distribution to the input space to make sure autoencoder, vanilla or VAE, learns to reconstruct the input more robustly regardless of scenic distortions.\n",
    "\n",
    "However, maybe your goal never was reconstruction and thus it doesn’t matter how good reconstruction is. Maybe you wanted to learn features and leverage it for other use. In that case, you wouldn’t care, mostly, about how well reconstruction happens. It is known that noise in input space doesn’t necessary help in better converage of feature space and thus feature learning is hampered. So, community came up with idea of introducing noise in the feature space instead of input space. It will obviously hurt the reconstruction but definitely learned features would be better and overall your feature vector would be more definitive of the latent space as a whole."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d7665aa",
   "metadata": {},
   "source": [
    "Question 4: What are undercomplete and overcomplete autoencoders? What is the main risk of an excessively undercomplete autoencoder? What about the main risk of an overcomplete autoencoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae89294e",
   "metadata": {},
   "source": [
    "Undercomplete AE:\n",
    "\n",
    "This is when our encoding output's dimension is smaller than our input's dimension.\n",
    "Essentially we reduced the dimension of our data (dimensionality reduction) with an undercomplete AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f555c6",
   "metadata": {},
   "source": [
    "Overcomplete AE:\n",
    "\n",
    "This is when our encoding output's dimension is larger than our input's dimension\n",
    "Essentially we increased the dimension of our data with an overcomplete AE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c622450",
   "metadata": {},
   "source": [
    "The main risk of an undercomplete autoencoder is that it may fail to reconstruct the inputs "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65256121",
   "metadata": {},
   "source": [
    "The main risk of an overcomplete autoencoder is that it just copy the inputs to the outputs without learning any useful featutre."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "045b2289",
   "metadata": {},
   "source": [
    "Question 5: How do you tie weights in a stacked autoencoder? What is the point of doing so?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb8ab8b1",
   "metadata": {},
   "source": [
    "To tie the weights of an encoder layer and its correspondiing decoder layer of a stacked autoencoder a common technique is to simply make the decoder weights equal to the transpose of the decpder weights. The reduces the number of parameters in the model by half often making training converge faster with less training and reducing the risk of overfitting the training dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "561f7d82",
   "metadata": {},
   "source": [
    "Queestion 6: What is a generative model? Can you name a type of generative autoencoder?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d476f1f9",
   "metadata": {},
   "source": [
    "A generative model is a model capable of randomly generating outputs that resemble the training instances. For example once trained successfully on the MNIST dataset a generative  model can be used to randomly generate realistic images of digits. The output dimensiion is typically similar to the training data. Some generative models can be parameterized for example to generate only some kinds of outputs.An example is variational autoencoder. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4e5b4ba",
   "metadata": {},
   "source": [
    "Question 6: What is a GAN? Can you name a few tasks where GANs can shine?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "667e6024",
   "metadata": {},
   "source": [
    "GANs are neural networks that learn to create synthetic data similar to some known input data. For instance, researchers have generated convincing images from photographs of everything from bedrooms to album covers, and they display a remarkable ability to reflect higher-order semantic logic."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a160894",
   "metadata": {},
   "source": [
    "Few Applicatiions are:\n",
    "\n",
    "\n",
    "Generate Examples for Image Datasets.\n",
    "Generate Photographs of Human Faces.\n",
    "Generate Realistic Photographs.\n",
    "Generate Cartoon Characters.\n",
    "Image-to-Image Translation.\n",
    "Text-to-Image Translation.\n",
    "Semantic-Image-to-Photo Translation.\n",
    "Face Frontal View Generation.\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d669fabd",
   "metadata": {},
   "source": [
    "Question 7:What are the main difficulties when training GANs?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "603e6679",
   "metadata": {},
   "source": [
    "GANs are notoriously difficult to train. Without the right hyperparameters, network architecture, and training procedure, the discriminator can overpower the generator, or vice-versa.\n",
    "\n",
    "In one common failure mode, the discriminator overpowers the generator, classifying generated images as fake with absolute certainty. When the discriminator responds with absolute certainty, it leaves no gradient for the generator to descend. This is partly why we built our discriminator to produce unscaled output rather than passing its output through a sigmoid function that would push its evaluation toward either 0 or 1.\n",
    "\n",
    "In another common failure mode, known as mode collapse, the generator discovers and exploits some weakness in the discriminator. You can recognize mode collapse in your GAN if it generates many very similar images regardless of variation in the generator input z. Mode collapse can sometimes be corrected by “strengthening” the discriminator in some way—for instance, by adjusting its training rate or by reconfiguring its layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e8ae5f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
